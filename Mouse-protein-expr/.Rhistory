NB.cm.valid <- confusionMatrix(NB.pred, validX$Class)
NB.cm.valid
### Neural network ###
set.seed(334)
# fit the model
NN.model = neuralnet::neuralnet(formula.NC, trainX,
hidden=c(14, 10, 8), linear.output = FALSE)
tablePred.NN <- function(model, data){
# make predictions using valid set
raw.pred <- data.frame(neuralnet::compute(model,
data.frame(data[,-ncol(data)]))$net.result)
# initialize target labels
labels <- c("c-CS-m", "c-CS-s", "c-SC-m", "c-SC-s",
"t-CS-m", "t-CS-s", "t-SC-m", "t-SC-s")
pred.label <- data.frame(max.col(raw.pred)) %>%
mutate(prediction=labels[max.col.raw.pred.])
# make predictions using valid set
preds <- as.factor(pred.label[,2])
confMat <- confusionMatrix(validX$Class, preds)
confMat
}
NN.cm.valid <- tablePred.NN(NN.model, validX)
NN.cm.valid
### multinomial logistic regression ###
set.seed(232)
# fit the model
MGR.model <- nnet::multinom(formula.NC, data = trainX, trace = F)
# make predictions using valid set
MGR.pred <- predict(MGR.model, newdata=validX)
# check reference and predicted classification
MGR.cm.valid <- confusionMatrix(validX$Class, MGR.pred)
MGR.cm.valid
# Custom Stacked Ensemble learner
stackLearner <- function(model1, model2, model3, testData, validData){
## --NB.model: model1 (Naive Bayes)
## --NN.model: model2 (Artificial Neural Network)
## --MGR.model: model3 (Multinomial Logistic regression)
# raw predictions from the base models
validpred1 <- predict(model1, validData, type= "raw")
validpred2 <- predict(model2, validData, type= "raw")
colnames(validpred2) <- colnames(validpred1)
validpred3 <- predict(model3, validData, type= "probs")
# Generate level-one dataset for training the ensemble meta-learner
basePred <- data.frame(validpred1, validpred2, validpred3, Class= validData$Class,
stringsAsFactors = F)
# Train the ensemble
set.seed(270)
modelStack <- train(Class~., data = basePred, method = "rf")
# Generate predictions on the test set
testPred1 <- predict(model1, newdata = testData,type= "raw")
testPred2 <- predict(model2, newdata = testData, type= "raw")
testPred3 <- predict(model3, newdata = testData,type= "probs")
# Using the base learner test set predictions,
# create the level-one dataset to feed to the ensemble
testPredLevelOne <- data.frame(testPred1, testPred2, testPred3,
Class= testX$Class, stringsAsFactors = F)
# estimate predictions over tested base models
colnames(testPredLevelOne) <- colnames(basePred)
combPred <- predict(modelStack, testPredLevelOne)
# Evaluate ensemble test performance
confMatrix <- confusionMatrix(combPred, testData$Class)
return(list(confMatrix, combPred))
}
# func call
stackResults  <- stackLearner(model1 = NB.model,
model2 = NN.model,
model3 = MGR.model,
testData = testX, validData = validX)
# Ensemble prediction matrix
ENS.confMat <- unlist(stackResults[1])
ENS.confMat
# Ensemble prediction matrix
ENS.confMat <- stackResults[1]
ENS.confMat
# Evaluate base learners test performances
#model1
NB.pred.test <- predict(NB.model, testX)
NB.cm.test <- confusionMatrix(NB.pred.test, testX$Class, mode='prec_recall')
NB.cm.test$table
# model2
NN.cm.test <- tablePred.NN(NN.model, testX)
NN.cm.test
# model3
MGR.pred.test <- predict(MGR.model, testX)
MGR.cm.test <- confusionMatrix(MGR.pred.test, testX$Class)
MGR.cm.test
## Plotting ROC curve of our best model --stacked ensemble learner
stack.ens.pred <- unlist(stackResults[2])
roc.pred <- as.ordered(stack.ens.pred)
# get aucs for every class label
result <- pROC::multiclass.roc(testX$Class, roc.pred, quiet = T,
levels = c("c-CS-m", "c-CS-s", "c-SC-m", "c-SC-s",
"t-CS-m", "t-CS-s", "t-SC-m", "t-SC-s"))
# plotting the classes that are significant to our learning outcomes
# normal learning: "c-CS-m"
rocModels <- function(pred, test){
roc.pred <- as.ordered(pred)
# get roc results for every class label
res<- pROC::multiclass.roc(test$Class, roc.pred, quiet = T,
levels = c("c-CS-m", "c-CS-s", "c-SC-m", "c-SC-s",
"t-CS-m", "t-CS-s", "t-SC-m", "t-SC-s"))
plot.roc(res$rocs[[1]],
print.auc=T,
legacy.axes = T)
# normal learning: "c-CS-s"
plot.roc(res$rocs[[2]],
add=T, col = 'red',
print.auc = T,
legacy.axes = T,
print.auc.adj = c(0,3))
# rescued learning: "t-CS-m"
plot.roc(res$rocs[[4]],add=T, col = 'blue',
print.auc=T,
legacy.axes = T,
print.auc.adj = c(0,5))
# failed learning: "t-CS-s"
plot.roc(res$rocs[[5]],
add=T, col = 'green',
print.auc = T,
legacy.axes = T,
print.auc.adj = c(0,7))
legend('bottomright',
legend = c('c-CS-m: NL-1','c-CS-s: NL-2',
't-CS-m: RL', 't-CS-s: FL'),
col=c('black','red','blue', 'green'),lwd=2)
}
rocModels(pred=stack.ens.pred, test = testX)
# plotting the classes that are significant to our learning outcomes
# normal learning: "c-CS-m"
rocModels <- function(pred, test){
roc.pred <- as.ordered(pred)
# get roc results for every class label
res<- pROC::multiclass.roc(test$Class, roc.pred, quiet = T,
levels = c("c-CS-m", "c-CS-s", "c-SC-m", "c-SC-s",
"t-CS-m", "t-CS-s", "t-SC-m", "t-SC-s"))
plot.roc(res$rocs[[1]],
print.auc=T,
legacy.axes = T, main="AUC plot")
# normal learning: "c-CS-s"
plot.roc(res$rocs[[2]],
add=T, col = 'red',
print.auc = T,
legacy.axes = T,
print.auc.adj = c(0,3))
# rescued learning: "t-CS-m"
plot.roc(res$rocs[[4]],add=T, col = 'blue',
print.auc=T,
legacy.axes = T,
print.auc.adj = c(0,5))
# failed learning: "t-CS-s"
plot.roc(res$rocs[[5]],
add=T, col = 'green',
print.auc = T,
legacy.axes = T,
print.auc.adj = c(0,7))
legend('bottomright',
legend = c('c-CS-m: NL-1','c-CS-s: NL-2',
't-CS-m: RL', 't-CS-s: FL'),
col=c('black','red','blue', 'green'),lwd=2)
}
rocModels(pred=stack.ens.pred, test = testX)
# Evaluate base learners test performances
#model1
NB.pred.test <- predict(NB.model, testX)
NB.cm.test <- confusionMatrix(NB.pred.test, testX$Class, mode='prec_recall')
NB.cm.test$table
# model2
NN.cm.test <- tablePred.NN(NN.model, testX)
NN.cm.test
# model3
MGR.pred.test <- predict(MGR.model, testX)
MGR.cm.test <- confusionMatrix(MGR.pred.test, testX$Class)
MGR.cm.test
rocModels(pred=NB.pred.test, test=testX)
tablePred.NN <- function(model, data){
# make predictions using valid set
raw.pred <- data.frame(neuralnet::compute(model,
data.frame(data[,-ncol(data)]))$net.result)
# initialize target labels
labels <- c("c-CS-m", "c-CS-s", "c-SC-m", "c-SC-s",
"t-CS-m", "t-CS-s", "t-SC-m", "t-SC-s")
pred.label <- data.frame(max.col(raw.pred)) %>%
mutate(prediction=labels[max.col.raw.pred.])
# make predictions using valid set
preds <- as.factor(pred.label[,2])
confMat <- confusionMatrix(validX$Class, preds)
return(list(preds,confMat))
}
NN.cm.valid <- tablePred.NN(NN.model, validX)
NN.cm.valid <- unlist(tablePred.NN(NN.model, validX))
NN.cm.valid[2]
NN.cm.valid[1]
NN.cm.valid <- tablePred.NN(NN.model, validX)
NN.cm.valid[1]
NN.cm.valid[2]
NN.cm.test[2]
NN.cm.test[1]
# model2
NN.cm.test <- tablePred.NN(NN.model, testX)
NN.cm.test[2]
NN.cm.test[2]$table
NN.cm.test <- unlist(NN.cm.test[2])
NN.cm.test$table
NN.cm.test
NN.cm.test <- NN.cm.test[2]
NN.cm.test$table
NN.cm.test
# model2
NN.cm.test <- tablePred.NN(NN.model, testX)
NN.cm.test <- NN.cm.test[2]
NN.cm.test
NN.cm.test[1]
NN.cm.test[2]
NN.cm.test[[2]]
NN.cm.test[[1]]
unlist(NN.cm.test)
# model2
NN.tablePred <- tablePred.NN(NN.model, testX)
NN.cm.test <- NN.tablePred[2]
NN.cm.test
NN.cm.test[1,]
NN.cm.test[]
NN.cm.test
unlist(NN.cm.test[1])
NN.cm.test
# model-2: Artificial Neural Network
evalMetrics(confMat = NN.tablePred[2])
# model-2: Artificial Neural Network
evalMetrics(confMat = NN.cm.test)
# model-2: Artificial Neural Network
rocModels(pred=NN.tablePred[2], test = testX)
# model-2: Artificial Neural Network
rocModels(pred=unlist(NN.tablePred[2]), test = testX)
Q
unlist(NN.tablePred[2])
# model2
NN.tablePred <- tablePred.NN(NN.model, testX)
# model-2: Artificial Neural Network
rocModels(pred=unlist(NN.tablePred[1]), test = testX)
# model-1: Naive Bayes
rocModels(pred=NB.pred.test, test=testX)
# model-2: Artificial Neural Network
rocModels(pred=unlist(NN.tablePred[1]), test = testX)
# model-3: Multi-nomial Logistic Regression
evalMetrics(confMat = MGR.cm.test, test = testX)
(pred=MGR.pred.test.test, test = testX)
# model-3: Multi-nomial Logistic Regression
rocModels(pred=MGR.pred.test.test, test = testX)
# model-3: Multi-nomial Logistic Regression
rocModels(pred=MGR.pred.test, test = testX)
#####################################
########## Feature Study ############
#####################################
## Method-1: Correlation Cut-off
rawData <- norm_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
#####################################
########## Feature Study ############
#####################################
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
# After inspecting the matrix, we set the correlation threshold at 0.75
# Apply correlation filter at 0.75
highlyCor <- findCorrelation(corMatNC1, 0.75)
#then we remove all the variable correlated with more 0.75.
reduced_data <- rawData[,-highlyCor]
## Method -2: Variable Importance
feat <- reduced_data
feat$Class <- nc.Class
# training `randomForest` to calculate feature importance
rf  <- randomForest(Class ~., data = feat)
var_imp <- varImp(rf, scale = FALSE)
# sort the score in decreasing order
var_imp_df <- data.frame(cbind(variable = rownames(var_imp), score = var_imp[,1]))
var_imp_df$score <- as.double(var_imp_df$score)
# plotting the rf_scores to determine threshold
ggplot(rf_scores, aes(x=reorder(variable, score), y=score)) +
geom_point() +
geom_segment(aes(x=variable,xend=variable,y=0,yend=score)) +
ggtitle("RF-feature plot") +
ylab("IncNodePurity") +
xlab("Variable Name") +
coord_flip()
ncortex.raw <- read.csv("https://docs.google.com/spreadsheets/d/1pWBv5zJPwyOP3vsY9AMLyuSF-ZQ-apPl/edit#gid=1571911879")
ncortex.raw <- read.csv("https://docs.google.com/spreadsheets/d/1pWBv5zJPwyOP3vsY9AMLyuSF-ZQ-apPl/edit#gid=1571911879",
header = T)
# setwd("~/Academics/gitProjects/myProjects/Mouse-protein-expr")
####### pacakges #######
packages <- c("readxl", "tidyverse", "psych", "corrplot", "randomForest",
"e1071", "caret", "neuralnet", "nnet", "NeuralSens","ipred",
"ggplot2", "FactoMineR", "factoextra", "devtools", "ggbiplot",
"pROC")
nb.cm.valid$overall[1:2]
ENS.confMat
# model-4: Stacked Ensemble Learner
evalMetrics(confMat = ENS.confMat)
evalMetrics <- function(confMat){
# metrics-1
print("The accuracy and kappa of the Naive Bayes model are")
print(round(confMat$overall[1:2] * 100,2))
# metrics-2
print("The precision, recall and F1-score for target classes are")
print(confMat$byClass[c(1,2,4,5),c(5,6,7)])
}
# model-1: Naive Bayes
evalMetrics(confMat = NB.cm.test)
# model-2: Artificial Neural Network
evalMetrics(confMat = NN.cm.test)
# model-3: Multi-nomial Logistic Regression
evalMetrics(confMat = MGR.cm.test)
# model-2: Artificial Neural Network
evalMetrics(confMat = NN.cm.test)
NN.cm.test <- NN.tablePred[2]
NN.cm.test
# model-2: Artificial Neural Network
evalMetrics(confMat = NN.cm.test)
# model-4: Stacked Ensemble Learner
evalMetrics(confMat = ENS.confMat)
stackResults[2]
source("~/Academics/gitProjects/myProjects/Mouse-protein-expr/main.R")
source("~/Academics/gitProjects/myProjects/Mouse-protein-expr/main.R")
rm(list = ls())
# setwd("~/Academics/gitProjects/myProjects/Mouse-protein-expr")
####### pacakges #######
packages <- c("readxl", "tidyverse", "psych", "corrplot", "randomForest",
"e1071", "caret", "neuralnet", "nnet", "NeuralSens","ipred",
"ggplot2", "FactoMineR", "factoextra", "devtools", "ggbiplot",
"pROC")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
######### data review ########
# Reading data file
# define the URL -- you could dynamically build this
# URL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls"
# download file
# download.file(URL, destfile="Data_Cortex_Nuclear.xls")
# load the file
ncortex.raw <- as.data.frame(read_excel("Data_Cortex_Nuclear.xls"))
head(ncortex.raw)
dim(ncortex.raw)
str(ncortex.raw)
# turning "warnings" off
options(warn=-1)
########## pre-processing - I  ##########
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# factorize target variable
ncortex$class <- as.factor(ncortex.raw$class)
# check categorical distribution
plot_bar(ncortex)
head(ncortex)
# imputing missing values
# check the columns with NAs
featNA <- names(which(sapply(ncortex, anyNA)))
dataNA <- ncortex[, featNA]
# check categorical distribution
plot_bar(ncortex)
# setwd("~/Academics/gitProjects/myProjects/Mouse-protein-expr")
####### pacakges #######
packages <- c("readxl", "tidyverse", "psych", "corrplot", "randomForest",
"e1071", "caret", "neuralnet", "nnet", "NeuralSens","ipred",
"DataExplorer", "ggplot2", "FactoMineR", "factoextra", "devtools",
"ggbiplot", "pROC")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
######### data review ########
# Reading data file
# define the URL -- you could dynamically build this
# URL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls"
# download file
# download.file(URL, destfile="Data_Cortex_Nuclear.xls")
# load the file
ncortex.raw <- as.data.frame(read_excel("Data_Cortex_Nuclear.xls"))
head(ncortex.raw)
dim(ncortex.raw)
str(ncortex.raw)
# turning "warnings" off
options(warn=-1)
########## pre-processing - I  ##########
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# factorize target variable
ncortex$class <- as.factor(ncortex.raw$class)
# check categorical distribution
plot_bar(ncortex)
head(ncortex)
# imputing missing values
# check the columns with NAs
featNA <- names(which(sapply(ncortex, anyNA)))
dataNA <- ncortex[, featNA]
# total number of NAs
sum(is.na(dataNA))
# check the distribution of NAs in each column
colSums(is.na(dataNA))
## Imputation
# computing mean of all columns using colMeans()
means <- colMeans(dataNA, na.rm = TRUE)
# replacing NA with mean value of each column
for(i in colnames(dataNA)){
dataNA[,i][is.na(dataNA[,i])] <- means[i]
}
# check missing values in our feature dataNC frame
sum(is.na(dataNA))
# replace the imputed features with the original dataNC
ncortex[,featNA] <- dataNA
# check basic statistics
summary(ncortex)
head(ncortex)
head(ncortex.raw)
exit()
q
q
clear
q()
q()
rm()
install.packages("plotrix")
library(plotrix)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white")
data <- c(19, 21, 54, 12, 36, 12)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white")
install.packages("lessR")
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"))
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
data <- c(25, 20, 10, 30, 15)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
data <- c(25, 20, 10, 30, 15)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
library(plotrix)
data <- c(25, 20, 10, 30, 15)
pie3D(data, col = hcl.colors(length(data), "Spectral"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "Viridus"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "Shade"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "Blue"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "blue"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "heatmap"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
pie3D(data, col = hcl.colors(length(data), "spectral"), border = "white",
mar = rep(1.75, 4),
labels = c("Action", "Adventure", "Sci-fi", "Sports", "Psych"),
explode = 0.1)
setwd("~/Academics/gitProjects/myProjects/Mouse-protein-expr")
knitr::opts_chunk$set(echo = TRUE)
packages <- c("readxl", "tidyverse", "psych", "corrplot", "randomForest",
"e1071", "caret", "neuralnet", "nnet", "NeuralSens","ipred",
"DataExplorer", "ggplot2", "FactoMineR", "factoextra", "devtools",
"ggbiplot", "pROC")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# define the URL -- you could dynamically build this
# URL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls"
# download file
# download.file(URL, destfile="Data_Cortex_Nuclear.xls")
# load the file
ncortex.raw <- as.data.frame(read_excel("../data/Data_Cortex_Nuclear.xls"))
head(ncortex.raw)
dim(ncortex.raw)
